{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, pandas, pickle, argparse\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import   hamming_loss\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.adapt import MLkNN\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "source": [
    "## Hyper-parameters:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_types= 10 # In our experiments, we use k= {3, 5, 10} top types.\n",
    "Path='./data/YAGO43K-ET/'\n",
    "Embedding_Path='./data/YAGO43K-ET/Preprocessed Files/YAGO43K-ConnectE.txt' \n",
    "\n",
    "labeled_size= 0.01 # size of labeled data, in our experiments we try 0.01, 0.1, 0.2, 0.9\n",
    "\n",
    "seed= 42 # random_seed to reproduce our results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pre-traind Emebddings of YAGO43k Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loading ConnectE embedding model For YAGO3-10 Dataset\n",
    "def load_embedding_model(Embedding_Path):\n",
    "    ConnectE_embedding = {}\n",
    "    \n",
    "    with open(Embedding_Path,'r') as inf:\n",
    "        for line in inf:\n",
    "            lisplit=line.split('\\t')\n",
    "            ConnectE_embedding[lisplit[0]]=eval(lisplit[1])\n",
    "    return ConnectE_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained embeddding, YAGO embedding.    \n",
    "entity_embeddings = load_embedding_model(Embedding_Path)\n",
    "\n",
    " ## Lookup Entity Types in YAGO43K:\n",
    "YAGO_ttrain = list(filter(None, [re.split('\\t', i.strip('\\n')) for i in open(PATH+'/YAGO43k_Entity_Type_train_clean.txt')]))\n",
    "YAGO_ttest = list(filter(None, [re.split('\\t', i.strip('\\n')) for i in open(PATH+'/YAGO43k_Entity_Type_test_clean.txt')]))\n",
    "YAGO_tvalid = list(filter(None, [re.split('\\t', i.strip('\\n')) for i in open(PATH+'/YAGO43k_Entity_Type_valid_clean.txt')]))\n",
    "\n",
    "YAGO_types=YAGO_ttrain+YAGO_ttest+YAGO_tvalid\n",
    "\n",
    "Types_df = pandas.DataFrame(YAGO_types)\n",
    "Types_df=Types_df.set_index([0]) \n",
    "\n",
    "Entities_Groups = Types_df.groupby(0).agg(lambda x: list(x)) # entities with multiple types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_entities_topTypes(embedding_vec, y_dict, top_types):\n",
    "    \n",
    "    # flatten y_true (list of lists) into one list to count the most frequent types.\n",
    "    y_true=list(y_dict.values())\n",
    "    y_true_flatten=sum(y_true, [])\n",
    "\n",
    "    # count top_types in FB15k dataset.\n",
    "    top_types=[key for key, _ in Counter(y_true_flatten).most_common(top_types)]\n",
    "\n",
    "    #filter embeddings for  top_types entities\n",
    "    entity_embedding_filter={}\n",
    "    y_true_filter={}\n",
    "\n",
    "    for ent, ttype in y_dict.items(): # y_true is a multi-label types (list of list)\n",
    "            \n",
    "        for ent_tt in ttype: \n",
    "                \n",
    "            if ent_tt in top_types:\n",
    "                entity_embedding_filter[ent]= embedding_vec[ent] # get the emb vec for entity\n",
    "                    \n",
    "                if ent in y_true_filter:\n",
    "                    y_true_filter[ent]+= [ent_tt]\n",
    "                else:\n",
    "                    y_true_filter[ent]= [ent_tt]\n",
    "                        \n",
    "    X_all=np.array(list(entity_embedding_filter.values()))\n",
    "    return X_all, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered vectors 42k out of 123k entities from YAGO dataset... \n",
    "embedding_vec={} \n",
    "y_dict={}\n",
    "\n",
    "for ent in entity_embeddings:\n",
    "    \n",
    "    if ent in entity_embeddings:\n",
    "        embedding_vec[ent]=  entity_embeddings[ent] \n",
    "        y_dict[ent]= Entities_Groups.loc[[ent]][1][0]\n",
    "        \n",
    "X_all, y_all= filter_entities_topTypes(embedding_filter, y_dict, top_types)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess labels as one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = preprocessing.MultiLabelBinarizer()\n",
    "y_encoded=label_encoder.fit_transform(list(y_true_filter.values()))\n",
    "labels = label_encoder.classes_.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function: Print Evaluation Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_results(y_test, y_pred):\n",
    "    #----------- Evaluation based on Precision, Recall, Accuracy and F1-score: -------#\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    precision = metrics.precision_score(y_test, y_pred, average='samples')\n",
    "    recall = metrics.recall_score(y_test, y_pred, average='samples')\n",
    "    f1 = metrics.f1_score(y_test, y_pred, average='samples')\n",
    "    Hloss= hamming_loss(y_test,  y_pred)\n",
    "    print(\"Evaluation results (acc. prec. rec. F1 & Hloss)-- Examples-based Averaged:\\n\\n{:.3f} & {:.3f} & {:.3f} & {:.3f} & {:.3f}\".format(accuracy, precision, recall, f1, Hloss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Split: train-valid-test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3143, 200), (2829, 200), (25466, 200))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train-valid-test dataset split into label-unlabelled (x_,x_u), (y_l, y_u)\n",
    "x_l, x_u, y_l, y_u = train_test_split(X_all, y_encoded,  train_size=labeled_size, random_state=seed)\n",
    "\n",
    "# split the dataset B into test & valid sets\n",
    "x_valid, x_test, y_valid, y_test=train_test_split(x_u, y_u, train_size=labeled_size, random_state=seed)\n",
    "print (\"Size of data: train-valid-test\" ,   x_l.shape[0], x_valid.shape[0], x_test.shape[0])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baselines: (Logistic Regressions, RandomForest, Embeddings, and DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 100\n",
    "n_patience=3\n",
    "early= EarlyStopping(monitor='val_loss', mode='min', patience=n_patience, restore_best_weights=True) "
   ]
  },
  {
   "source": [
    "### 1) DNN baseline:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DNN_model=keras.Sequential(name=\"DNNModel\")\n",
    "DNN_model.add(layers.Dense(128, activation='relu', input_shape=(X_all.shape[1],)))\n",
    "DNN_model.add(layers.Dense(y_encoded.shape[1], activation='sigmoid'))\n",
    "DNN_model.summary()\n",
    "\n",
    "# Compile model\n",
    "DNN_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train the DNN baseline\n",
    "DNN_model.fit(A_x, A_y, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[early], validation_data=(B_valid, y_valid), verbose=0)\n",
    "\n",
    "# print evaluation of DNN\n",
    "DNN_pred[DNN_pred <= 0.5] = 0\n",
    "DNN_pred[DNN_pred > 0.5] = 1\n",
    "DNN_pred=DNN_pred.astype(np.int64)\n",
    "\n",
    "evaluation_results(y_test, DNN_pred)"
   ]
  },
  {
   "source": [
    "## 2) Logisitc Regression:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lr_MCLF = BinaryRelevance(LogisticRegression(solver='liblinear'))\n",
    "Lr_MCLF.fit(A_x, A_y)\n",
    "y_lr=Lr_MCLF.predict(B_test)\n",
    "\n",
    "evaluation_results(y_test, y_lr.toarray())"
   ]
  },
  {
   "source": [
    "## 3) RandomForest Baseline:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_MCLF = BinaryRelevance(RandomForestClassifier(random_state=seed))\n",
    "rf_MCLF.fit(A_x, A_y)\n",
    "y_rf=rf_MCLF.predict(B_test)\n",
    "evaluation_results(y_test, y_rf.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Embedding (KNN) Baseline: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'k': range(1,1), 's': [0.5, 0.7, 1.0]}\n",
    "\n",
    "clf = GridSearchCV(MLkNN(), parameters, n_jobs= -1)\n",
    "clf.fit(A_x, A_y)\n",
    "y_KNN=clf.predict(B_test)\n",
    "evaluation_results(y_test, y_KNN.toarray())"
   ]
  },
  {
   "source": [
    "--- "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Approach (Teacher-Student Algorithm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We use the best baseline as an initial teacher model to generate pseudo-labels for the unlabeled data\n",
    "- We train the student model on the labeled&pseudo-labeld data.\n",
    "- Replace the teacher model with student model and generate new pseudo-labeled data. \n",
    "- Repeat until the student model is converaged."
   ]
  },
  {
   "source": [
    "### The structure of student model:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "studentModel=keras.Sequential(name=\"StudentModel\")\n",
    "studentModel.add(layers.Dense(128, activation='relu', input_shape=(X_all.shape[1],)))\n",
    "studentModel.add(layers.Dropout(rate=0.25))\n",
    "studentModel.add(layers.Dense(y_encoded.shape[1], activation='sigmoid'))\n",
    "studentModel.summary()\n",
    "\n",
    "studentModel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations=5\n",
    "\n",
    "# get the pseudo-labels initially from the teacher model \n",
    "teacher_pred=DNN_model.predict(B_test)\n",
    "\n",
    "for i in range(n_iterations):\n",
    "\n",
    "    ## Train the Student Model on the Labeled Dataset:\n",
    "    studentModel.fit(A_x, A_y, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[early], validation_data=(B_valid, y_valid), verbose=0)\n",
    "\n",
    "    ## Train the student model on the pseudo-labeled data:\n",
    "    studentModel.fit(B_test, teacher_pred, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[early], validation_data=(B_valid, y_valid), verbose=0)\n",
    "\n",
    "    # We use the DNN baseline as our initial teacher.\n",
    "    teacher_pred=studentModel.predict(B_test) \n",
    "\n",
    "\n",
    "teacher_pred[teacher_pred <= 0.5] = 0\n",
    "teacher_pred[teacher_pred > 0.5] = 1\n",
    "teacher_pred=teacher_pred.astype(np.int64)\n",
    "evaluation_results(y_test, teacher_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DAIKIRI)",
   "language": "python",
   "name": "daikiri"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}